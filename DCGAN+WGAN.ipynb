{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims, mean, ones\n",
    "import numpy as np\n",
    "from numpy.random import randn, randint\n",
    "from keras.datasets import mnist\n",
    "from keras import backend\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, BatchNormalization \n",
    "from keras.initializers import RandomNormal\n",
    "from keras.constraints import Constraint\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = expand_dims(X_train, axis=-1)\n",
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "\n",
    "class ClipConstraint(Constraint):\n",
    "    def __init__(self, clip_value):\n",
    "        self.clip_value = clip_value\n",
    " \n",
    "    def __call__(self, weights):\n",
    "        return backend.clip(weights, -self.clip_value, self.clip_value)\n",
    " \n",
    "    def get_config(self):\n",
    "        return {'clip_value': self.clip_value}\n",
    " \n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return backend.mean(y_true * y_pred)\n",
    " \n",
    "def define_critic(in_shape=(28,28,1)):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    const = ClipConstraint(0.01)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const, input_shape=in_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    opt = RMSprop(lr=0.00005)\n",
    "    model.compile(loss=wasserstein_loss, optimizer=opt)\n",
    "    return model\n",
    " \n",
    "def define_generator(latent_dim):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    model = Sequential()\n",
    "    n_nodes = 128 * 7 * 7\n",
    "    model.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(1, (7,7), activation='tanh', padding='same', kernel_initializer=init))\n",
    "    return model\n",
    " \n",
    "def define_gan(generator, critic):\n",
    "    for layer in critic.layers:\n",
    "        if not isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(critic)\n",
    "    opt = RMSprop(lr=0.00005)\n",
    "    model.compile(loss=wasserstein_loss, optimizer=opt)\n",
    "    return model\n",
    " \n",
    "def train(g_model, c_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=128, n_critic=5):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    half_batch = int(n_batch / 2)\n",
    "    for i in tqdm(range(n_steps)):\n",
    "        for _ in range(n_critic):\n",
    "            X_real = dataset[randint(0, dataset.shape[0], half_batch)]\n",
    "            y_real = ones((half_batch, 1))\n",
    "            c_loss1 = c_model.train_on_batch(X_real, y_real)\n",
    "            x_input = randn(latent_dim * half_batch)\n",
    "            x_input = x_input.reshape(half_batch, latent_dim)\n",
    "            X_fake = generator.predict(x_input)\n",
    "            y_fake = -ones((half_batch, 1))\n",
    "            c_loss2 = c_model.train_on_batch(X_fake, y_fake)\n",
    "        x_input = randn(latent_dim * n_batch)\n",
    "        X_gan = x_input.reshape(n_batch, latent_dim)\n",
    "        y_gan = ones((n_batch, 1))\n",
    "        g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "\n",
    "latent_dim = 100\n",
    "critic = define_critic()\n",
    "generator = define_generator(latent_dim)\n",
    "gan_model = define_gan(generator, critic)\n",
    "train(generator, critic, gan_model, X_train, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
